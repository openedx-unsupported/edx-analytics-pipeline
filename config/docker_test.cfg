# Safe defaults that can be used by unit and acceptance tests.
[job-conf]
# The third-party docker containers we use run everything as "root". Setting this environment variable on all child
# processes allows us to write to HDFS as the hadoop user instead. Otherwise we end up writing a mix of "hadoop" user
# owned files and "root" owned files, which are often not readable by the "hadoop" user.
mapred.child.env = HADOOP_USER_NAME=hadoop

[retcode]
# The following return codes are the recommended exit codes for Luigi.
# They are in increasing level of severity (for most applications).
already_running = 10
missing_data = 20
not_run = 25
task_failed = 30
scheduling_error = 35
unhandled_exception = 40

[hive]
release = apache
version = 1.0
database = default
warehouse_path = s3://fake/warehouse/

[database-export]
database = to_database
credentials = s3://fake/credentials.json

[database-import]
database = from_database
credentials = s3://fake/credentials.json
destination = s3://fake/warehouse/

[map-reduce]
engine = hadoop
marker = s3://fake/marker/
remote_log_level = DEBUG

[event-logs]
# pattern = [".*tracking.log-(?P<date>\d{8}).*\.gz", ".*tracking.notalog-(?P<date>\d{8}).*\.gz"]
pattern = [".*tracking.log-(?P<date>\\\\d{8}).*\\\\.gz", ".*tracking.notalog-(?P<date>\\\\d{8}).*\\\\.gz"]
expand_interval = 2 days
source = ["s3://fake/input/", "s3://fake/input2/"]

[segment-logs]
pattern = [".*segment.log-(?P<date>\\\\d{8}).*\\\\.gz", ".*segment.notalog-(?P<date>\\\\d{8}).*\\\\.gz"]
source = ["s3://fake/segment/input/", "s3://fake/segment/input2/"]

[event-export]
output_root = s3://fake/
environment = unittest
config = s3://fake/event_export/config.yaml
gpg_key_dir = s3://fake/event_export/gpg-keys/
gpg_master_key = master@key.org
required_path_text = FakeServerGroup

[event-export-course]
output_root = s3://fake/

[obfuscation]
explicit_event_whitelist = explicit_events.tsv
xblock_obfuscation_config = xblock_obfuscation_config.yml

[id-codec]
seed_value = 42

[manifest]
threshold = 500
input_format = org.edx.hadoop.input.ManifestTextInputFormat
lib_jar = s3://fake/oddjob.jar
path = /tmp/fake/manifest/

[user-activity]
output_root = s3://fake/activity/
overwrite_n_days = 3

[enrollments]
interval_start = 2013-11-01
overwrite_n_days = 14

[location-per-course]
interval_start = 2013-11-01
overwrite_n_days = 14

[geolocation]
geolocation_data = s3://fake/geo.dat

[calendar]
interval = 2012-01-01-2020-01-01

[course-catalog]
catalog_url = http://acceptance.test/api/courses/v2

[course-structure]
api_root_url = acceptance.test
access_token = acceptance

[otto-database-import]
database = otto
credentials = s3://fake/otto_creds.json

[videos]
dropoff_threshold = 0.05
overwrite_n_days = 5

[module-engagement]
alias = roster
number_of_shards = 5

[course-catalog-api]
partner_short_codes = ["openedx"]
api_root_url = http://example.com/api/v1/

[ccx]
enabled = false

[edx-rest-api]
client_id = dummy_client_id
client_secret = dummy_client_secret
auth_url = http://localhost:8000/oauth2/access_token/
cache_root = /tmp/edx-rest-api

[problem_response]
report_output_root = /tmp/problem-response-reports/

[course-list]
api_root_url = http://localhost:8000/api/courses/v1/courses/

[course-blocks]
api_root_url = http://localhost:8000/api/courses/v1/blocks/
