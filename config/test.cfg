# Safe defaults that can be used by unit and acceptance tests.

[hive]
release = apache
database = default
warehouse_path = s3://fake/warehouse/

[database-export]
database = to_database
credentials = s3://fake/credentials.json

[database-import]
database = from_database
credentials = s3://fake/credentials.json
destination = s3://fake/warehouse/

[map-reduce]
engine = hadoop
marker = s3://fake/marker/
remote_log_level = DEBUG

[event-logs]
pattern = .*tracking.log-(?P<date>\d{8}).*\.gz
          .*tracking.notalog-(?P<date>\d{8}).*\.gz
expand_interval = 2 days
source = s3://fake/input/
         s3://fake/input2/

[event-export]
output_root = s3://fake/
environment = unittest
config = s3://fake/event_export/config.yaml
gpg_key_dir = s3://fake/event_export/gpg-keys/
gpg_master_key = master@key.org
required_path_text = FakeServerGroup

[manifest]
threshold = 500
input_format = oddjob.ManifestTextInputFormat
lib_jar = s3://fake/oddjob.jar
path = s3://fake/manifest/

[user-activity]
output_root = s3://fake/activity/

[enrollments]
blacklist_date = 2014-08-18

[enrollment-reports]
src = s3://fake/input/
destination = s3://fake/enrollment_reports/output/
offsets = s3://fake/enrollment_reports/offsets.tsv
blacklist = s3://fake/enrollment_reports/course_blacklist.tsv
history = s3://fake/enrollment_reports/enrollment_history.tsv

[geolocation]
geolocation_data = s3://fake/geo.dat

[calendar]
interval = 2012-01-01-2020-01-01
